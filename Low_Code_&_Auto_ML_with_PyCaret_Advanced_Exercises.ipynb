{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rahul-Chahar/02-01-2022/blob/main/Low_Code_%26_Auto_ML_with_PyCaret_Advanced_Exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1h0N2hfZ6tcv"
      },
      "source": [
        "# 1 - Objective\n",
        "\n",
        "\n",
        "The objective of this notebook will be to tackle the same classification problem from the Kickstarter notebook using the power of PyCaret. We will be exploring more advanced features and capabilities of PyCaret along the way:\n",
        "\n",
        "-  __Getting Data:__ Learn how to import default datasets from PyCaret repository\n",
        "\n",
        "-  __Custom Environment Setup:__ Learn how to setup a custom experiment in PyCaret with advanced data transformations!\n",
        "\n",
        "-  __Compare Models:__ Learn how to compare multiple machine learning models for the given classification task based on model evaluation metrics\n",
        "\n",
        "-  __Create Model:__ Learn how to create specific classifical models, perform stratified cross validation and evaluate classification metrics\n",
        "\n",
        "-  __Tune Model:__ Learn how to automatically tune the hyper-parameters of classification models in different ways\n",
        "\n",
        "-  __Ensemble Model:__ Learn how to automatically ensemble classification models in different ways\n",
        "\n",
        "-  __Plot Model:__ Learn how to analyze model performance using various diagnostic plots\n",
        "\n",
        "-  __Interpret Model:__ Learn how to interpret and explain classification models in different ways using XAI\n",
        "\n",
        "-  __Finalize Model:__ Learn how to finalize the best model at the end of the experiment\n",
        "\n",
        "-  __Predict Model:__ Learn how to make predictions on new / unseen data \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xUUNBEK9fiF"
      },
      "source": [
        "# 2 - Install PyCaret\n",
        "\n",
        "The first step to get started is to install `pycaret`. \n",
        "\n",
        "Run all the cells below to install necessary dependencies for some of the advanced capabilities to use with PyCaret along with PyCaret itself\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGee7xS4x4-r"
      },
      "outputs": [],
      "source": [
        "!pip install explainerdashboard\n",
        "!pip install optuna\n",
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdNDx_3T6eYd"
      },
      "outputs": [],
      "source": [
        "!pip install pycaret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zs_YI9nLW2X"
      },
      "outputs": [],
      "source": [
        "!pip install -U jinja2==3.0.3 # https://github.com/pycaret/pycaret/issues/2591 to bypass import errors later on"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Restart the Kernel now and then proceed by running the following cells as usual"
      ],
      "metadata": {
        "id": "R3RMtGdiI7P9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDXu175n5umR"
      },
      "source": [
        "# Low-Code & Auto-ML with PyCaret - Advanced\n",
        "\n",
        "Welcome to this hands-on workshop session where we will learn about leveraging the very popular low-code and auto-ml library PyCaret!\n",
        "\n",
        "![](https://i.imgur.com/cWzC62x.png)\n",
        "\n",
        "\n",
        "The focus of this notebook is to continue from where we left off in the kickstarter notebook and dive into more complex features in PyCaret! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBjlghVB_GRL"
      },
      "source": [
        "## 2.1 - Enable Interactive Visuals\n",
        "\n",
        "If you are using Google Colab, please run the following to enable interactive visuals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ox2fyZcI92YX"
      },
      "outputs": [],
      "source": [
        "from pycaret.utils import enable_colab\n",
        "enable_colab()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16rlL6r2_Sxr"
      },
      "source": [
        "# 3 - Binary Classification\n",
        "\n",
        "The objective in this notebook will be to solve a predictive machine learning classification problem. To be more specific, it is going to be binary classification.\n",
        "\n",
        "Binary classification is a supervised machine learning technique where the key objective is to predict a response variable given a set of independent variables (features). The response variable is categorical, having two discrete class labels, such as 1/0, Yes/No, Positive/Negative, Default/Not-Default and so on. \n",
        "\n",
        "A few real world use cases for classification are listed below:\n",
        "\n",
        "- Fraud detection models to detect if a transaction is fraudulent or not fraudulent\n",
        "- A \"pass or fail\" test method or quality control in factories, i.e. deciding if a specification has or has not been met â€“ a go/no-go classification.\n",
        "- Sentiment Analysis -> Positive or Negative"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6jnvOgRAEI9"
      },
      "source": [
        "# 4 - PyCaret Classification Module\n",
        "\n",
        "PyCaret's `classification` module (`pycaret.classification`) is a supervised machine learning module which is used for training, tuning, evaluating and deploying classification models. \n",
        "\n",
        "The PyCaret `classification` module can be used for Binary or Multi-class classification problems. It has over 18 algorithms and 14 plots to analyze the performance of models. Be it hyper-parameter tuning, ensembling or advanced techniques like stacking, PyCaret's classification module has it all.\n",
        "\n",
        "Do check out [`pycaret.classification`'s documentation](https://pycaret.gitbook.io/docs/get-started/quickstart#classification)and [full-fledged APIs](https://pycaret.readthedocs.io/en/latest/api/classification.html) as needed!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zexdqoj5A5Yj"
      },
      "source": [
        "# 5 - Getting the Data\n",
        "\n",
        "We will be using a popular open-source dataset, called the \"Adult\" dataset also known as \"Census Income\" dataset.\n",
        "\n",
        "Key Objective: Predict whether income exceeds $50K/yr based on census data\n",
        "\n",
        "You can download the data from the original source [found here](https://archive.ics.uci.edu/ml/datasets/adult) \n",
        "\n",
        "\n",
        "and load it using `pandas` or you can use PyCaret's data respository to load the data using the `get_data()` function (This will require an internet connection).\n",
        "\n",
        "The PyCaret version of the dataset is slightly more processed and is a subset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Cp3VIHKEw3a"
      },
      "source": [
        "## 5.1 - Data Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtwP_mlV_O5U"
      },
      "outputs": [],
      "source": [
        "from pycaret.datasets import get_data\n",
        "dataset = get_data('income')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8dbQMZXDA0B"
      },
      "outputs": [],
      "source": [
        "dataset.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uw26ZoTyDDPv"
      },
      "outputs": [],
      "source": [
        "dataset.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTT44R1eEz8i"
      },
      "source": [
        "## 5.2 - Split Data into Train-Test Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xZzVYFDDWGT"
      },
      "source": [
        "In order to demonstrate the `predict_model()` function on unseen data, a holdout sample of 15% records has been withheld from the original dataset to be used for predictions. \n",
        "\n",
        "This will be your true unseen test dataset to be used at the end once all training is complete as a simulation of live real data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jnCNKC4DI1s"
      },
      "outputs": [],
      "source": [
        "# create train - test datasets\n",
        "data_train = dataset.sample(frac=0.85, random_state=42)\n",
        "data_test = dataset.drop(data_train.index)\n",
        "\n",
        "# reset row numbers \\ indices\n",
        "data_train.reset_index(inplace=True, drop=True)\n",
        "data_test.reset_index(inplace=True, drop=True)\n",
        "print('Data for Modeling: ' + str(data_train.shape))\n",
        "print('Unseen Data For Predictions: ' + str(data_test.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yys8hCjGE7lM"
      },
      "source": [
        "## 5.3 - Understanding the Data\n",
        "\n",
        "Let's try to understand our dataset now in terms of the given attributes.\n",
        "\n",
        "We use a dataset modified dataset from UCI called [Adult Data Set\n",
        "](https://archive.ics.uci.edu/ml/datasets/adult). \n",
        "\n",
        "This dataset contains census data and details about various aspects of people and their income.\n",
        "\n",
        "There are 32561 samples and 14 features. \n",
        "\n",
        "Brief descriptions of each column are as follows:\n",
        "\n",
        "- __age__: continuous; age of the person\n",
        "\n",
        "- __workclass__: categorical; working class of the person;\n",
        "Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
        "\n",
        "- __education__: categorical; educational qualification of the person;\n",
        "Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
        "\n",
        "- __education-num__: discrete numeric; educational qualification of the person as a encoded value; \n",
        "\n",
        "- __marital-status__: categorical; marital status of the person; \n",
        "Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
        "\n",
        "- __occupation__: categorical; occupation of the person;\n",
        "Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
        "\n",
        "- __relationship__: categorical; relationship information;\n",
        "Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
        "\n",
        "- __race__: categorical; race information;\n",
        "White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
        "\n",
        "- __sex__: categorical; gender of the person; \n",
        "Female, Male.\n",
        "\n",
        "- __capital-gain__: continuous; overall capital gain \n",
        "\n",
        "- __capital-loss__: continuous; overall capital loss\n",
        "\n",
        "- __hours-per-week__: continuous; working hours per week\n",
        "\n",
        "- __native-country__: categorical; native country of residence;\n",
        "United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.\n",
        "\n",
        "- **`income >50K`**: Whether the income of the person is more than $50K (1=yes, 0=no) Target Column\n",
        "\n",
        "The original dataset and data dictionary can be [found here](https://archive.ics.uci.edu/ml/datasets/adult)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZIICgVcEo0J"
      },
      "outputs": [],
      "source": [
        "data_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPCl_PC0IdnT"
      },
      "source": [
        "# 6 - PyCaret Environment Setup\n",
        "\n",
        "The `setup()` function initializes the environment in `pycaret` and creates the transformation pipeline to prepare the data for modeling and deployment. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-iaerQ9IPAb"
      },
      "outputs": [],
      "source": [
        "from pycaret.classification import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vRKqTudKj0s"
      },
      "outputs": [],
      "source": [
        "experiment = setup(data=data_train, target='income >50K', session_id=42) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEfJVmGzNlar"
      },
      "source": [
        "Once the setup has been succesfully executed it prints the information grid which contains several important pieces of information. \n",
        "\n",
        "Most of the information is related to the pre-processing pipeline which is constructed when `setup()` is executed. \n",
        "\n",
        "We are not doing any extensive pre-processing to start with, however a few important things to note at this stage include:\n",
        "\n",
        "- **session_id :**  A pseudo-random number distributed as a seed in all functions for later reproducibility. If no `session_id` is passed, a random number is automatically generated that is distributed to all functions. In this experiment, the `session_id` is set as `123` for later reproducibility.\n",
        "\n",
        "- **Target Type :**  Binary or Multiclass. The Target type is automatically detected and shown. There is no difference in how the experiment is performed for Binary or Multiclass problems. All functionalities are identical.\n",
        "\n",
        "- **Label Encoded :**  When the Target variable is of type string (i.e. 'Yes' or 'No') instead of 1 or 0, it automatically encodes the label into 1 and 0 and displays the mapping (0 : No, 1 : Yes) for reference. In this experiment no label encoding is required since the target variable is of type numeric.\n",
        "\n",
        "- **Original Data :**  Displays the original shape of the dataset. In this experiment (27677, 14) means 27,677 samples and 14 features including the target column. \n",
        "\n",
        "- **Missing Values :**  When there are missing values in the original data this will show as True. For this experiment there are several missing values in the dataset. \n",
        "\n",
        "- **Numeric Features :**  The number of features inferred as numeric. In this dataset, 4 features are inferred as numeric. \n",
        "\n",
        "- **Categorical Features :**  The number of features inferred as categorical. In this dataset, 9 features are inferred as categorical.\n",
        "\n",
        "- **Transformed Train Set :**  Displays the shape of the transformed training set. Notice that the original shape of (27677, 24) is transformed into (19373, 104) for the transformed train set and the number of features have increased to 104 due to categorical encoding \n",
        "\n",
        "- **Transformed Test Set :**  Displays the shape of the transformed test/hold-out set. There are 8304 samples in test/hold-out set. This split is based on the default value of 70/30 that can be changed using the `train_size` parameter in setup. Can also be used as a validation set if you make decisions of choosing the best model based on this subset.\n",
        "\n",
        "Notice how a few tasks that are imperative to perform modeling are automatically handled such as missing value imputation, categorical encoding etc. \n",
        "\n",
        "Most of the parameters in `setup()` are optional and used for customizing the pre-processing pipeline.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltiNyUM1WRqM"
      },
      "source": [
        "# 7 - Comparing all Models\n",
        "\n",
        "Comparing all models to evaluate performance is the recommended starting point for modeling once the setup is completed (unless you exactly know what kind of model you need, which is often not the case). \n",
        "\n",
        "This function trains all models in the model library and scores them using stratified cross validation for metric evaluation. The output prints a score grid that shows average Accuracy, AUC, Recall, Precision, F1, Kappa, and MCC accross the folds (10 by default) along with training times.\n",
        "\n",
        "We use a 3-fold cross validation and focus on the F1-score metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qkd99INNJtu"
      },
      "outputs": [],
      "source": [
        "best_model = compare_models(fold=3, sort='F1')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaJFsL-o80yR"
      },
      "source": [
        "Looks like boosting models have taken up the leaderboard above!\n",
        "\n",
        "What we will do next is focus on the top model and apply different data transformation techniques to see if it improves \n",
        "in terms of performance"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8 - Profiling your Dataset\n",
        "\n",
        "We can use `pandas_profiling` to generate a nice data profile report of our dataset to get an idea of the major issues in our data which we can perhaps fix in the next section"
      ],
      "metadata": {
        "id": "tMug00eEssuj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8km0my9s_CEt"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nq-UbCYB_Ldf"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9 - Advanced Data Transformations\n",
        "\n",
        "In this section we will setup another classification experiment but we will make some additional transformations to the dataset:\n",
        "\n",
        "- **imputation_type :**  We do not use the default imputation methodology anymore in PyCaret which does mean imputation for numeric and constant imputation for categorical. Here we use iterative ML based imputation using a lightGBM model\n",
        "\n",
        "- **remove_multicollinearity :**  We set this to true to remove features which might be highly correlated\n",
        "\n",
        "- **multicollinearity_threshold :**  We set this to 0.9 to remove features which might be having more than 0.9 correlation with other features\n",
        "\n",
        "- **fix_imbalance :**  We set this to True because we have imbalanced classes and hence this will internally use the SMOTE oversampling technique to generate synthetic data to create more samples for the minority class"
      ],
      "metadata": {
        "id": "kuCo3nBQs69R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIgGmPTKDkDo"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcyKkXhvOF1R"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cxkTUOSN6nu"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we build the top 5 models from the last time with our new data transformations"
      ],
      "metadata": {
        "id": "3OHGmVy7C3cL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_9wuZOOERlQ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO4nO4TJ9ITa"
      },
      "source": [
        "# 10 - Create ML Models\n",
        "\n",
        "`create_model` is one of the most important functions in PyCaret and is often the starting point or foundation behind most of the PyCaret functionalities. \n",
        "\n",
        "As the name suggests this function trains and evaluates a model using cross validation that can be set with `fold` parameter. The output prints a score grid that shows Accuracy, AUC, Recall, Precision, F1, Kappa and MCC by fold. \n",
        "\n",
        "For the remaining part of this tutorial, we will work with the following model which is our top performing model\n",
        "\n",
        "The selection is based on the best model with the top F1-score:\n",
        "\n",
        "```\n",
        "- Light Gradient Boosting Machine ('lightgbm')\n",
        "```\n",
        "\n",
        "There are 18 classifiers available in the model library of PyCaret. To see list of all classifiers either check the `docstring` or use `models` function to see the library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjKiV_9R8wb_"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5S_BHg0d-HXs"
      },
      "source": [
        "## 10.1 - Create Light Gradient Boosting Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oED8zl4z9-nz"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chwjm4g3-QlR"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J9zknWb_Apc"
      },
      "source": [
        "# 11 - Tune ML Models\n",
        "\n",
        "When a model is created using the `create_model()` function it uses the default hyperparameters to train the model. \n",
        "\n",
        "In order to tune hyperparameters, the [`tune_model()`](https://pycaret.readthedocs.io/en/latest/api/classification.html#pycaret.classification.tune_model) function is used. \n",
        "\n",
        "This function automatically tunes the hyperparameters of a model using `Randomized Search` on a pre-defined search space. The output prints a score grid that shows Accuracy, AUC, Recall, Precision, F1, Kappa, and MCC by fold for the best model. \n",
        "\n",
        "To use the custom search grid, you can pass `custom_grid` parameter in the `tune_model` function (see 9.2 Logistic Regression tuning below)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LquZIjo__zdS"
      },
      "source": [
        "## 11.1 Tune Light Gradient Boosting Model with Randomized Search\n",
        "\n",
        "Uses Randomized Search method to tune the model on F1-score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvwCLsJURvcg"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11.2 Tune Light Gradient Boosting Model with Bayesian Search\n",
        "\n",
        "Uses Bayesian Search method to tune the model on F1-score using Optuna\n",
        "\n",
        "The Tree-structured Parzen Estimator (TPE) is a sequential model-based optimization (SMBO) approach. SMBO methods sequentially construct models to approximate the performance of hyperparameters based on historical measurements, and then subsequently choose new hyperparameters to test based on this model."
      ],
      "metadata": {
        "id": "rFNyZ24bDdkU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjGMq4fpTUQT"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVfaxTD_CGQ7"
      },
      "source": [
        "Looks like tuning didn't yield any significant improvements. That could also be because the number of trials we tried our were very less."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQpLYCMAgeV6"
      },
      "source": [
        "# 12 - Ensembling ML Models\n",
        "\n",
        "This functionality helps in ensembling a given model in different ways"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12.1 - Create a simple decision tree model"
      ],
      "metadata": {
        "id": "0ldxJVXCE4XW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LpLb7QW_4ko"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12.2 - Ensemble model by Bagging\n",
        "\n",
        "Trains multiple models independently in parallel and combines their predictions to build one big model"
      ],
      "metadata": {
        "id": "-8HOK7-RE7kZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnSDwLp9ghzD"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcSiiRwzAH1J"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12.3 - Ensemble model by Boosting\n",
        "\n",
        "Trains multiple models sequentially where one model tries to learn from the mistakes of the previous model, and combines their predictions to build one big model"
      ],
      "metadata": {
        "id": "fbZYwAlVFFJ7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nu8cTyg5g-Ib"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUFUWEFNALbe"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12.4 - Ensemble model by Blending\n",
        "\n",
        "This function trains a Soft Voting / Hard Voting Majority Rule classifier for select models passed in the `estimator_list` parameter."
      ],
      "metadata": {
        "id": "p85xpxZqFiPV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aa1HWTjhbDB"
      },
      "outputs": [],
      "source": [
        "# train individual models to blend\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fuJOXMlhvJR"
      },
      "outputs": [],
      "source": [
        "# blend individual models based on soft labels i.e predicted probabilities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sQxcjixiHp5"
      },
      "outputs": [],
      "source": [
        "# blend individual models based on hard labels i.e predicted labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12.5 - Ensemble model by Stacking\n",
        "\n",
        "This function trains a meta-model over select estimators passed in the `estimator_list` parameter. Which means predictions of the initial models go as inputs into the meta model which makes the final predictions"
      ],
      "metadata": {
        "id": "P6Wr_8F9GDwL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXvNTajLj-E5"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUJSdKHFCmzS"
      },
      "source": [
        "# 13 - Plot ML Model Evaluation Diagnostics\n",
        "\n",
        "Before model finalization, the `plot_model()` function can be used to analyze and evaluate the model performance across different aspects such as AUC, confusion_matrix, decision boundary etc. \n",
        "\n",
        "This function takes a trained model object and returns a plot based on the test / hold-out set. \n",
        "\n",
        "There are many different plots available, please see the `plot_model()` docstring for the list of available plots."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGZm6x7hy1c8"
      },
      "source": [
        "## 13.1 - Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-42E3FvVB6-5"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yggs4ndfzIhr"
      },
      "source": [
        "## 13.2 - Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NZj1xwZzP6s"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13.3 - ROC AUC Curve"
      ],
      "metadata": {
        "id": "tYy48cKcGY9i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SR6r60eBmsBC"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13.4 - Classification Report"
      ],
      "metadata": {
        "id": "u5y5Z-LaGcR4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rs9iUgqCmweQ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1WCdgUNzakV"
      },
      "source": [
        "*Another* way to analyze the performance of models is to use the `evaluate_model()` function which displays a user interface for all of the available plots for a given model. It internally uses the `plot_model()` function. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_DFzG8QzVjj"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGKQttDyoKLj"
      },
      "source": [
        "# 14 - Interpret your ML Models with XAI"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14.1 - SHAP Summary Plot\n",
        "\n",
        "Shows effects of each feature on model predictions based on SHAP values for the entire test dataset. \n",
        "\n",
        "Positive values have a positive influence on model (pushes it to predict the positive class) and negative values have a negative influence on the model (pushes it to predict the negative class)"
      ],
      "metadata": {
        "id": "uOSn51eNGjgN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RF0OL-fDoMGm"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14.2 - SHAP Partial Dependence Plots\n",
        "\n",
        "Shows effects of specific features on model predictions based on SHAP values for the entire test dataset. \n",
        "\n",
        "Positive values have a positive influence on model (pushes it to predict the positive class) and negative values have a negative influence on the model (pushes it to predict the negative class)"
      ],
      "metadata": {
        "id": "wHauRnb4G6a6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1VAK9nm4bZM"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F46LZwix6SO_"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uA-hd8g4OaN"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14.3 - SHAP Reasoning Plot\n",
        "\n",
        "Shows effects of specific features on model predictions based on SHAP values for a specific row of the test dataset.\n",
        "\n",
        "Positive values have a positive influence on model (pushes it to predict the positive class) and negative values have a negative influence on the model (pushes it to predict the negative class)"
      ],
      "metadata": {
        "id": "P0j6dShwHBnd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OA-RvWf88-xc"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3R0Rwbr8uaQ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYmjj10m9Qu_"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCcZfIvy9T66"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14.4 - XAI Explainer Dashboard\n",
        "\n",
        "This generates an interactive dashboard for a trained model consisting of evaluation metrics and SHAP based explanation artifacts"
      ],
      "metadata": {
        "id": "APtbSo_yHYdk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dCsYRKGrwGu"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We need to open a tunnel since we can't open a webpage inside colab"
      ],
      "metadata": {
        "id": "pw5-59z7H9hC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0u6nqfTY3mWQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Terminate open tunnels if exist\n",
        "\n",
        "# Setting the authtoken (optional)\n",
        "# Get your authtoken from https://dashboard.ngrok.com/auth\n",
        "\n",
        "\n",
        "# Open an HTTPs tunnel on port 8050 for http://localhost:8050\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZSNNP491XcL"
      },
      "source": [
        "# 15 - Finalize Model for Deployment\n",
        "\n",
        "Model finalization is the last step in the experiment. \n",
        "\n",
        "A normal machine learning workflow in PyCaret starts with `setup()`, followed by comparing all models using `compare_models()` and shortlisting a few candidate models (based on the metric of interest) to perform several modeling techniques such as hyperparameter tuning, ensembling, stacking etc. (more on advanced techniques in the next tutorial!).\n",
        "\n",
        "This workflow will eventually lead you to the best model for use in making predictions on new and unseen data. \n",
        "\n",
        "\n",
        "The `finalize_model()` function fits the model onto the complete dataset **including** the test/hold-out sample (30% in this case). The purpose of this function is to **train the model on the complete dataset** before it is deployed in production."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irSq_ddO0o8M"
      },
      "outputs": [],
      "source": [
        "final_lgbm = finalize_model(lgbm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNQ5XdCD2Hjb"
      },
      "outputs": [],
      "source": [
        "#Final Light Gradient Boosting Model to be used for deployment\n",
        "final_lgbm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vZubVkC4JJC"
      },
      "source": [
        "# 16 - Predict on unseen / new datasets\n",
        "\n",
        "The `predict_model()` function is also used to predict on any new / unseen datasets. \n",
        "\n",
        "The only difference from section 11 above is that this time we will pass the `data_test` parameter. `data_test` is the variable created at the beginning of the tutorial and contains 15% of the original dataset which was never exposed to PyCaret. (see section 5 for explanation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e546Ez4H3xe1"
      },
      "outputs": [],
      "source": [
        "new_predictions = predict_model(final_lgbm, data=data_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6P85ORUO4iss"
      },
      "outputs": [],
      "source": [
        "new_predictions.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCGjrHJh4ojA"
      },
      "source": [
        "The `Label` and `Score` columns are added onto the `data_test` set. \n",
        "\n",
        "Label is the prediction and score is the probability of the prediction. \n",
        "\n",
        "Notice that predicted results are concatenated to the original dataset while all the data transformations are automatically performed in the background. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jn_7ZZgO42cs"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(new_predictions['income >50K'], new_predictions['Label']))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Low-Code & Auto-ML with PyCaret - Advanced Exercises.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}